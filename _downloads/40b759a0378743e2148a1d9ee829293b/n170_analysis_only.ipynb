{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nN170 Analysis Only\n===============================\n\nThis notebook runs only the data analysis part of N170 notebook.\n\nLook at the notes to see how this can be run on the web with binder or google collab.\n\nAll of the additional notes are removed; only the code cells are kept.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Imports\nfrom muselsl import stream, list_muses, view, record\nfrom multiprocessing import Process\nfrom mne import Epochs, find_events\nfrom time import time, strftime, gmtime\nimport os\n#from stimulus_presentation import n170\nos.chdir('../')\nfrom utils import utils\nfrom collections import OrderedDict\nimport warnings\nwarnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Skipping these steps                                                                                                  # ---------------------\n\nStep 1: Connect to an EEG Device\nStep 2: Apply the EEG Device and Wait for Signal Quality to Stabilize\nStep 3: Run the Experiment\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load Data\n---------------------\n\nWe will use the\n`MNE sample dataset <https://mne.tools/stable/overview/datasets_index.html?#sample>`_\nwhich is a combined MEG/EEG recording with an audiovisual task.\n\nFirst we will load the dataset from MNE, have a quick look at the data,\nand extract the EEG data that we will use for this example.\n\nNote that if you are running this locally, the following cell will download\nthe example dataset, if you do not already have it.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "subject = 1\nsession = 1\n\n#raw = utils.load_data('visual/N170', sfreq=256., \neegnb_data_path = '/c/Ubuntu_WSL/Code/libraries_of_mine/github/eeg-notebooks_old/data' \nraw = utils.load_data(eegnb_data_path + '/visual/N170', sfreq=256., \n                              subject_nb=subject, session_nb=session)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualize the power spectrum\n----------------------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#%matplotlib inline\nraw.plot_psd()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Filteriing\n----------------------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raw.filter(1,30, method='iir')\nraw.plot_psd(fmin=1, fmax=30);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Epoching\n----------------------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create an array containing the timestamps and type of each stimulus (i.e. face or house)\nevents = find_events(raw)\nevent_id = {'House': 1, 'Face': 2}\n\n# Create an MNE Epochs object representing all the epochs around stimulus presentation\nepochs = Epochs(raw, events=events, event_id=event_id, \n                        tmin=-0.1, tmax=0.8, baseline=None,\n                                        reject={'eeg': 75e-6}, preload=True, \n                                                        verbose=False, picks=[0,1,2,3])\nprint('sample drop %: ', (1 - len(epochs.events)/len(events)) * 100)\nepochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Epoch average\n----------------------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#%matplotlib inline\nconditions = OrderedDict()\nconditions['House'] = [1]\nconditions['Face'] = [2]\n\nfig, ax = utils.plot_conditions(epochs, conditions=conditions, \n                                        ci=97.5, n_boot=1000, title='',\n                                                                        diff_waveform=(1, 2))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}